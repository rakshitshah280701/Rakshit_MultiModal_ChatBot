<img width="1440" alt="Screenshot 2025-06-12 at 12 24 18â€¯AM" src="https://github.com/user-attachments/assets/23fa223c-fc8c-4981-ba3a-4cec704fe3ab" />

```markdown
# ğŸ§  Rakshit Multimodal ChatBot

A full-stack AI chatbot that accepts text and images, runs OCR to extract and locate text from uploaded images, and communicates with GPT-4o to provide intelligent responses based on both the image content and user queries.

## ğŸš€ Features

- ğŸ”¤ **Text + Image Input:** Supports chat via plain text or images with text (e.g. posters, screenshots).
- ğŸ§¾ **OCR Processing:** Uses EasyOCR to extract text and bounding box positions from images.
- ğŸ§  **LLM Integration:** Sends both extracted image data and user query to OpenAI GPT-4o for contextual understanding.
- ğŸ–¼ï¸ **Annotated Image Preview:** Displays images with overlaid OCR text and bounding boxes in the UI.
- âš™ï¸ **FastAPI Backend:** Handles image upload, OCR, prompt structuring, and LLM communication.
- ğŸŒ **Modern React Frontend:** Chat UI built using React with typewriter effects, image previews, and rich responses.

## ğŸ“¦ Tech Stack
ğŸ–¥ï¸ Frontend
- React â€“ Component-based UI development
- Tailwind CSS â€“ Utility-first styling
- Axios â€“ API calls to the FastAPI backend
- File Upload â€“ Image input for OCR

âš™ï¸ Backend
- FastAPI â€“ High-performance API framework for Python
- CORS Middleware â€“ Enables cross-origin requests
- JSON Encoder â€“ Encodes OCR results safely for API responses

ğŸ§  AI & OCR
- EasyOCR â€“ Extracts text and bounding boxes from images
- OpenAI GPT-4o â€“ Multimodal LLM used for response generation
- PIL & NumPy â€“ Image processing and pixel data handling


## ğŸ› ï¸ How It Works

1. User sends a message or uploads an image.
2. Image (if any) is processed via EasyOCR â†’ OCR text + position info extracted.
3. Structured prompt is sent to OpenAI API with:
   - Text message
   - OCR summary (e.g. â€œOffer: 50% off located at top-centerâ€)
   - Annotated image preview (base64)
4. Response from GPT-4o is displayed in the chat window.

## ğŸ“‚ Project Structure

```
```
Rakshit\_MultiModal\_ChatBot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”œâ”€â”€ ocr_utils.py        # EasyOCR processing + bounding box
â”‚   â””â”€â”€ .env                # API keys (ignored in Git)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/components/
â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚   â”‚   â”œâ”€â”€ ChatBubble.jsx
â”‚   â”‚   â”œâ”€â”€ Inputbar.jsx
â”‚   â”‚   â””â”€â”€ OCROverlay.jsx
â”‚   â””â”€â”€ public/
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
````

## ğŸ§ª Getting Started

### ğŸ“¦ Backend (FastAPI)

cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Add your OpenAI key to `.env`
echo "OPENAI_API_KEY=your-key-here" > .env

# Start the server
uvicorn main:app --reload
````

### ğŸ’» Frontend (React)

```bash
cd frontend
npm install
npm start
```

---

## ğŸ§  Sample Prompt to LLM

```json
{
  "role": "system",
  "content": "You are an assistant that analyzes OCR results from images. 'Grand Sale' is located at top-center. '50% OFF' is located at center. Use this to answer any questions."
}
```

---

## ğŸ” Notes

* `.env` file is excluded from Git using `.gitignore`
* Backend and frontend are fully decoupled with API communication
* OCR overlays do not leak into LLM â€” only structured insights are passed

---

## ğŸ™Œ Author

Built by **Rakshit Shah**
For demos, contributions, or collabs â€” reach out via [LinkedIn](https://www.linkedin.com/in/rakshitshah280701)

---
